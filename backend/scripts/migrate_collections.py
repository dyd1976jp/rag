#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Milvusé›†åˆè¿ç§»è„šæœ¬

å°†ç°æœ‰é›†åˆè¿ç§»åˆ°æ”¯æŒåŠ¨æ€å­—æ®µçš„æ–°schemaã€‚
"""

import os
import sys
import logging
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from app.rag.collection_manager import collection_manager
from pymilvus import connections, Collection, utility
from app.core.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def list_existing_collections() -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰ç°æœ‰é›†åˆ"""
    try:
        if not collection_manager.connect():
            logger.error("æ— æ³•è¿æ¥åˆ°MilvusæœåŠ¡å™¨")
            return []
        
        collections = collection_manager.list_collections()
        logger.info(f"å‘ç° {len(collections)} ä¸ªé›†åˆ: {collections}")
        return collections
    
    except Exception as e:
        logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {e}")
        return []


def analyze_collection(collection_name: str) -> Dict[str, Any]:
    """åˆ†æé›†åˆçš„å½“å‰çŠ¶æ€"""
    try:
        info = collection_manager.get_collection_info(collection_name)
        
        if not info.get("exists", False):
            return {"exists": False}
        
        logger.info(f"\n=== é›†åˆåˆ†æ: {collection_name} ===")
        logger.info(f"æè¿°: {info.get('description', 'N/A')}")
        logger.info(f"åŠ¨æ€å­—æ®µæ”¯æŒ: {info.get('enable_dynamic_field', False)}")
        logger.info(f"å®ä½“æ•°é‡: {info.get('num_entities', 0)}")
        
        logger.info("å­—æ®µåˆ—è¡¨:")
        for field in info.get("fields", []):
            logger.info(f"  - {field['name']}: {field['type']} (ä¸»é”®: {field.get('is_primary', False)})")
            if field.get('dimension'):
                logger.info(f"    ç»´åº¦: {field['dimension']}")
            if field.get('max_length'):
                logger.info(f"    æœ€å¤§é•¿åº¦: {field['max_length']}")
        
        logger.info("ç´¢å¼•åˆ—è¡¨:")
        for index in info.get("indexes", []):
            logger.info(f"  - {index['field_name']}: {index.get('params', {})}")
        
        return info
    
    except Exception as e:
        logger.error(f"åˆ†æé›†åˆ {collection_name} å¤±è´¥: {e}")
        return {"exists": False, "error": str(e)}


def backup_collection_data(collection_name: str) -> bool:
    """å¤‡ä»½é›†åˆæ•°æ®ï¼ˆå¯é€‰å®ç°ï¼‰"""
    try:
        collection = Collection(collection_name)
        num_entities = collection.num_entities
        
        if num_entities == 0:
            logger.info(f"é›†åˆ {collection_name} ä¸ºç©ºï¼Œæ— éœ€å¤‡ä»½")
            return True
        
        logger.warning(f"é›†åˆ {collection_name} åŒ…å« {num_entities} æ¡æ•°æ®")
        logger.warning("æ³¨æ„: å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒè‡ªåŠ¨æ•°æ®è¿ç§»ï¼Œè¯·æ‰‹åŠ¨å¤‡ä»½é‡è¦æ•°æ®")
        
        # TODO: å®ç°æ•°æ®å¤‡ä»½é€»è¾‘
        # è¿™é‡Œå¯ä»¥æ·»åŠ å°†æ•°æ®å¯¼å‡ºåˆ°æ–‡ä»¶çš„é€»è¾‘
        
        return True
    
    except Exception as e:
        logger.error(f"å¤‡ä»½é›†åˆ {collection_name} å¤±è´¥: {e}")
        return False


def migrate_collection(collection_name: str, force: bool = False) -> bool:
    """è¿ç§»å•ä¸ªé›†åˆ"""
    try:
        logger.info(f"\nğŸ”„ å¼€å§‹è¿ç§»é›†åˆ: {collection_name}")
        
        # åˆ†æå½“å‰é›†åˆ
        info = analyze_collection(collection_name)
        
        if not info.get("exists", False):
            logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return False
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ”¯æŒåŠ¨æ€å­—æ®µ
        if info.get("enable_dynamic_field", False):
            logger.info(f"âœ… é›†åˆ {collection_name} å·²æ”¯æŒåŠ¨æ€å­—æ®µï¼Œæ— éœ€è¿ç§»")
            return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        num_entities = info.get("num_entities", 0)
        if num_entities > 0 and not force:
            logger.warning(f"âš ï¸  é›†åˆ {collection_name} åŒ…å« {num_entities} æ¡æ•°æ®")
            logger.warning("æ•°æ®è¿ç§»éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼Œä½¿ç”¨ --force å‚æ•°å¼ºåˆ¶è¿ç§»ï¼ˆå°†ä¸¢å¤±æ•°æ®ï¼‰")
            return False
        
        # å¤‡ä»½æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if num_entities > 0:
            logger.info("æ­£åœ¨å¤‡ä»½æ•°æ®...")
            if not backup_collection_data(collection_name):
                logger.error("æ•°æ®å¤‡ä»½å¤±è´¥ï¼Œä¸­æ­¢è¿ç§»")
                return False
        
        # åˆ›å»ºæ–°çš„é›†åˆåç§°
        new_collection_name = f"{collection_name}_migrated"
        backup_collection_name = f"{collection_name}_backup"
        
        # è·å–å‘é‡ç»´åº¦ï¼ˆä»ç°æœ‰å­—æ®µä¸­æ¨æ–­ï¼‰
        dimension = 768  # é»˜è®¤ç»´åº¦
        for field in info.get("fields", []):
            if field.get("dimension"):
                dimension = field["dimension"]
                break
        
        logger.info(f"ä½¿ç”¨å‘é‡ç»´åº¦: {dimension}")
        
        # åˆ›å»ºæ–°é›†åˆ
        logger.info(f"åˆ›å»ºæ–°é›†åˆ: {new_collection_name}")
        new_collection = collection_manager.create_collection(
            collection_name=new_collection_name,
            dimension=dimension,
            drop_existing=True
        )
        
        if not new_collection:
            logger.error("åˆ›å»ºæ–°é›†åˆå¤±è´¥")
            return False
        
        # åˆ›å»ºç´¢å¼•
        logger.info("åˆ›å»ºç´¢å¼•...")
        if not collection_manager.create_indexes(new_collection):
            logger.error("åˆ›å»ºç´¢å¼•å¤±è´¥")
            return False
        
        # é‡å‘½åé›†åˆï¼ˆMilvusä¸ç›´æ¥æ”¯æŒé‡å‘½åï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†ï¼‰
        logger.info("é‡å‘½åé›†åˆ...")
        
        # 1. å°†åŸé›†åˆé‡å‘½åä¸ºå¤‡ä»½
        if utility.has_collection(collection_name):
            # ç”±äºMilvusä¸æ”¯æŒç›´æ¥é‡å‘½åï¼Œæˆ‘ä»¬éœ€è¦æç¤ºç”¨æˆ·æ‰‹åŠ¨å¤„ç†
            logger.warning(f"è¯·æ‰‹åŠ¨å¤„ç†ä»¥ä¸‹æ­¥éª¤:")
            logger.warning(f"1. å¦‚æœéœ€è¦ä¿ç•™åŸæ•°æ®ï¼Œè¯·å¤‡ä»½é›†åˆ {collection_name}")
            logger.warning(f"2. åˆ é™¤åŸé›†åˆ: utility.drop_collection('{collection_name}')")
            logger.warning(f"3. å°†æ–°é›†åˆ {new_collection_name} é‡å‘½åä¸º {collection_name}")
            
            if force:
                logger.info(f"å¼ºåˆ¶æ¨¡å¼ï¼šåˆ é™¤åŸé›†åˆ {collection_name}")
                utility.drop_collection(collection_name)
                
                # ç”±äºMilvusä¸æ”¯æŒé‡å‘½åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒåçš„æ–°é›†åˆ
                final_collection = collection_manager.create_collection(
                    collection_name=collection_name,
                    dimension=dimension,
                    drop_existing=True
                )
                
                if final_collection:
                    collection_manager.create_indexes(final_collection)
                    logger.info(f"âœ… é›†åˆ {collection_name} è¿ç§»å®Œæˆ")
                    
                    # æ¸…ç†ä¸´æ—¶é›†åˆ
                    if utility.has_collection(new_collection_name):
                        utility.drop_collection(new_collection_name)
                    
                    return True
        
        logger.info(f"âœ… æ–°é›†åˆ {new_collection_name} åˆ›å»ºå®Œæˆï¼ˆæ”¯æŒåŠ¨æ€å­—æ®µï¼‰")
        return True
    
    except Exception as e:
        logger.error(f"è¿ç§»é›†åˆ {collection_name} å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Milvusé›†åˆè¿ç§»å·¥å…·")
    parser.add_argument("--collection", "-c", help="æŒ‡å®šè¦è¿ç§»çš„é›†åˆåç§°")
    parser.add_argument("--all", "-a", action="store_true", help="è¿ç§»æ‰€æœ‰é›†åˆ")
    parser.add_argument("--force", "-f", action="store_true", help="å¼ºåˆ¶è¿ç§»ï¼ˆå°†ä¸¢å¤±ç°æœ‰æ•°æ®ï¼‰")
    parser.add_argument("--analyze-only", action="store_true", help="ä»…åˆ†æé›†åˆï¼Œä¸æ‰§è¡Œè¿ç§»")
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ Milvusé›†åˆè¿ç§»å·¥å…·å¯åŠ¨")
    
    # è¿æ¥åˆ°Milvus
    if not collection_manager.connect():
        logger.error("âŒ æ— æ³•è¿æ¥åˆ°MilvusæœåŠ¡å™¨")
        return 1
    
    try:
        # è·å–é›†åˆåˆ—è¡¨
        if args.collection:
            collections_to_process = [args.collection]
        elif args.all:
            collections_to_process = list_existing_collections()
        else:
            collections_to_process = list_existing_collections()
            if not collections_to_process:
                logger.info("æ²¡æœ‰å‘ç°ä»»ä½•é›†åˆ")
                return 0
            
            print("\nå‘ç°ä»¥ä¸‹é›†åˆ:")
            for i, name in enumerate(collections_to_process, 1):
                print(f"{i}. {name}")
            
            choice = input("\nè¯·é€‰æ‹©è¦è¿ç§»çš„é›†åˆç¼–å·ï¼ˆæˆ–è¾“å…¥ 'all' è¿ç§»æ‰€æœ‰é›†åˆï¼‰: ").strip()
            
            if choice.lower() == 'all':
                pass  # å¤„ç†æ‰€æœ‰é›†åˆ
            elif choice.isdigit() and 1 <= int(choice) <= len(collections_to_process):
                collections_to_process = [collections_to_process[int(choice) - 1]]
            else:
                logger.error("æ— æ•ˆé€‰æ‹©")
                return 1
        
        # å¤„ç†é›†åˆ
        success_count = 0
        total_count = len(collections_to_process)
        
        for collection_name in collections_to_process:
            if args.analyze_only:
                analyze_collection(collection_name)
            else:
                if migrate_collection(collection_name, args.force):
                    success_count += 1
        
        if not args.analyze_only:
            logger.info(f"\nğŸ“Š è¿ç§»å®Œæˆ: {success_count}/{total_count} ä¸ªé›†åˆè¿ç§»æˆåŠŸ")
        
        return 0 if success_count == total_count else 1
    
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 1
    finally:
        collection_manager.disconnect()


if __name__ == "__main__":
    exit(main())
